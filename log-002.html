<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Event-driven backend for small teams — Jainam Shah</title>

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&family=Inter:wght@400;500&display=swap"
        rel="stylesheet">

    <!-- Styles -->
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <main>
        <div class="back-link">
            <a href="logs.html">← Back to logs</a>
        </div>

        <article>
            <header>
                <h1>Event-driven backend for small teams</h1>
                <div class="article-meta">
                    <span class="log-meta">Backend · Architecture</span>
                    <span class="log-date">November 2024</span>
                </div>
            </header>

            <h2>Context</h2>
            <p>Small team (3 devs) building a SaaS product. Needed architecture that could handle 10x growth without
                complete rewrites, but couldn't over-engineer for uncertain scale.</p>

            <p>We were at 500 users, expecting to hit 5k within a year. Classic startup dilemma: build for scale you
                don't have yet, or risk painful rewrites later.</p>

            <h2>Approach</h2>
            <p>Started with simple REST API, then gradually introduced event sourcing for critical user actions. Used
                PostgreSQL as both primary store and event log to avoid operational complexity.</p>

            <p>The key insight was selective event sourcing. Not everything needs to be an event — only the
                business-critical operations that benefit from auditability and replay capability.</p>

            <h2>Key Decisions</h2>
            <ul>
                <li>Events only for business-critical operations (payments, user state changes)</li>
                <li>CRUD for everything else until proven otherwise</li>
                <li>Single PostgreSQL database to minimize deployment complexity</li>
                <li>Background job processing with simple retry logic</li>
                <li>Event store as a table, not a separate system</li>
            </ul>

            <h2>Implementation Details</h2>
            <p>Used a simple events table with JSON payloads. Event handlers were just functions that could be called
                synchronously or queued for background processing.</p>

            <p>This gave us the benefits of event sourcing (auditability, replay, eventual consistency) without the
                operational overhead of Kafka or EventStore.</p>

            <h2>Trade-offs</h2>
            <p>Sacrificed some theoretical scalability for operational simplicity. Team could deploy and debug easily,
                which mattered more at our stage than perfect architecture.</p>

            <p>We knew we'd eventually need to extract services and use proper message queues, but this approach bought
                us 18 months of rapid development.</p>

            <h2>Outcome</h2>
            <p>Handled 5x user growth with minimal changes. When we did need to scale, the event foundation made it
                straightforward to extract services.</p>

            <p>The event log became invaluable for debugging production issues and understanding user behavior patterns.
            </p>
        </article>

        <footer>
            <p>© Jainam Shah · <a href="logs.html">All Logs</a> · <a href="index.html">Home</a></p>
        </footer>
    </main>
</body>

</html>